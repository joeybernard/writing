Using Parallel Shells

More and more often, people are using clusters of machines to work on larger and larger computational problems. Using clusters allows you to take a problem that was essentially intractable and make it actually doable. This is great for solving the problem at hand, but it introduces a new problem. How do you interact with this cluster? In most cases, some kind of grid or scheduling software is installed to handle running the actual working code, but there is still maintenance work that needs to be handled. In this article, we'll cover a few of the options available in the open source community. There are several parallel shells available and each provides a slightly different set of behaviors. Hopefully you'll find one which fits your needs. All of these shells should be available from your local distro. If not, you can download the source for them directly from the links given at the end of this article.

The first shell we'll look at is dish (the diligence shell). This shell is one of the simpler ones, but still very useful. It can be used to connect to a series of hosts and either run some command on them, or change the password for the connecting user name on them. By default, dish uses ssh to connect to the remote hosts. This can be changed by using the option "-c <name>", where <name> is the name of the program to use to make the connection. We could use "-c rsh" to use rsh to make the connection. This means that we could use dish to interact with switches, databases, etc., as long as the device has a command line tool that you can use to make the connection. 

The list of hosts to connect to can be defined a few different ways. The most direct way is simply on the command line. It can take the form of "host1 host2 host3 ...", or if you wish to include usernames for connecting you can use the format "user1@host1 user2@host2 ...". If you have a large number of hosts, it will likely make more sense to store these host names in a file and get dish to read in the file. This can be done by using the option "-g <filename>" where <filename> is a file which contains the list of hosts, one host per line. You can enter the password for each host as dish connects to that host, or if you have the same password on all hosts you can give it once by using the option "-p <passwd>". Again, if you have a large number of hosts with different passwords on each you can use the option "-P <filename>" where <filename> is a file which will have one line for each user account on each host. These lines take the form of "password[:username[:host]]", allowing you to have maximum flexibility with which hosts and/or user accounts you connect to.

Now that you're connected, what can you do? The first thing you might want to do is change the password on these remote hosts. This can be done by using the option "-n <passwd>" where <passwd> is the new password to set. Or you may have some command you want to run on each host, like "who" to see which users are logged in on each host. To do this, you would use the option "-e who". You can specify a connection part when giving a command to run, as well. If you do, you can't use the options "-c" or "-e" at the same time as this type of command. If you wish to do this, you use the option "-E" instead. For example, to connect to each host by ssh and get the current date and time, you would use "-E 'ssh $host date'". Internally to dish, "$host" expands to the current host being connected to.

By default, dish connects to each host in sequence. This means dish connects to the first host and executes the given command, then when it finishes it connects to the second host, and so on until the list of hosts is exhausted. If you wish, you can also put in a delay between hosts with the option "-s [<time>]". This tells dish to wait "time" seconds between finishing with the first host and going on to the next host. If you want to actually connect to the hosts in parallel, there are two options. The first is to use the command line option "-F". This tells dish to go into fork and disconnect mode. This means that dish forks off for each connection to a host and disconnects from the local console. All output from the backgrounded connections gets routed to /dev/null, unless logging is being used. If you wish to keep the output on the current concole, you can use the command line option "-f" instead.

As an example, say you wanted to connect to a group of hosts and get the current system time and hostname from each. You could simply execute

  dish -c ssh -e "uname && date" jbernard@fundy.ace-net.ca jbernard@mahone.ace-net.ca

This will connect to the two machines fundy.ace-net.ca and mahone.ace-net.ca as the user jbernard using ssh. dish will ask for a password to use, and once you type that in, it will connect to each host in sequence. The output will look like

  spawn ssh jbernard@fundy.ace-net.ca uname && date
  jbernard@fundy.ace-net.ca's password:
  Linux
  Mon Dec 7 16:21:51 AST 2009
  spawn ssh jbernard@mahone.ace-net.ca uname && date
  jbernard@mahone.ace-net.ca's password:
  Linux
  Mon Dec 7 16:21:44 AST 2009

There are several options for logging your work with dish. The simplest is to use the command line option "-l <file>". This simply redirects output from the spawned processes to the file given. If you would prefer to have the output sorted, you can use the command line option "-L <name>" to tell dish to redirect output from each spawned process into a file with a name of the form "<name>_<user@host>.log". This gives you a log of the output from the remote commands being executed, but if you wanted detailed records of what was actually run? You can use the command line option "-j" to tell dish to record the command invoked on the remote hosts in a journal file located at "$HOME/.dish/journal".

The last major task for maintaining a cluster is distributing files. You can do this by using the included utility dicp. To copy a file to a group of hosts, you would execute "dicp -g hosts_file local_file :remote_file". In this example, "hosts_file" contains the remote hosts you want to send the file to.

Another parallel shell is dsh, or distributed shell. This shell has several changes to how it behaves. The list of hosts to connect to can be given by using the command line option "-m host1,host2,...". You can also use the format "user1@host1, user2@host2, ...". If you have a large number of hosts, you can specify them in a file and tell dsh by using the command line option "-f <filename>". You can also tell dsh what connection program to use by using the command line option "-r <connector>".

Just as in dish, dsh can be run in both serial and parallel mode. To run in serial mode, you would use the command line option "-w". This tells dsh to wait for one remote host to finish before going onto the next one. To run in parallel, You can use the command line option "-c" to tell dsh to run in concurrent mode. If you have a really large list of hosts in your list, you may want to limit the number of connections at any one time. You can do this by using the command line option "-F <limit>", which tells dsh to only fork off <limit> processes at a time. When running in concurrent mode, the output can get a bit messy. The command line option "-M" tells dsh to prepend the machine name to each line of output. This makes it a bit easier to sort out the output from individual remote hosts.

The last parallel shell we'll look at today is pdsh. This parallel shell can execute a given command, just like the previous shells. The unique behaviour in pdsh is that if you neglect to give a command, pdsh will enter interactive mode. In interactive mode, any command you execute at the console will get mirrored to all of the connected remote hosts. The other unique behaviour in pdsh is the use of loadable modules. In this way, pdsh can be extended without having to recompile the whole program. To get a detailed list of all of the currently loaded modules, you can use the command line option "-L". A shorter list can be gotten by using the command line option "-V". The most common modules used are likely to be "rsh" (which is actually the default connection mechanism), "ssh" and "exec". But this may vary from installation to installation.

There are several ways to select your connection mechanism. If all hosts are to be connected to in the same way, you can use the command line option "-R module" where "module" is the connection mechanism. So, if you wanted to connect using ssh, you would use "-R ssh". If you wish to use different connection methods for each host, you can specify it in the list of host machines by using the format "[rcmd_type:][user@][host]". The list of remote connections is handed in to pdsh by using the command line option "-w". An example of this might be "-w ssh:user1@host1,rsh:user2@host2". When using ssh, you should keep in mind that pdsh won't ask you for a password, so you will need to set up ssh keys to login without needing a password. There is also a way of using shortcuts if you use a format of name+number in your node names. For example, let's say you have ten nodes and they are named node1, node2, node3, ..., node10. You can specify this list by using the command line option "-w node[1-10]".

When running remote commands, there are several options to control execution. To set the connect timeout, use the command line option "-t seconds". The default here is 10 seconds. You can also set the amount of time for remote execution by using the command line option "-u seconds". The default here is no limit. To control the number of concurrent connections, you use the command line option "-f num". The default here is 32. The output from these remote commands ends up on the console, prepended with the hostname for the remote host. You can turn this off by using the command line option "-N".

pdsh uses control key combinations to allow the user to interact with the running and pending threads. Typing ctrl-c lists the status of the current threads. Typing ctrl-c again within 1 second terminates pdsh. Typing ctrl-c and then ctrl-z within 1 second of each other kills off all pending threads, but leaves all currently running threads.

Hopefully this article has sparked some interest in some of the tools available for maintain whole clusters of machines. As you can see, each tool has its own niche. And these are just the beginning. You may be interested in looking at even more robust packages, like taktuk. In any case, go out in parallel.


Links
http://www.cs.rpi.edu/~wheelf/dish/index.html
http://www.netfort.gr.jp/~dancer/software/dsh.html.en
https://computing.llnl.gov/linux/pdsh.html
http://taktuk.gforge.inria.fr/
