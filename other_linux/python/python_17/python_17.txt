@Title (probably something like 'The Python column')
Optimizing Python Code



@standfirst - 22 words
After you have profiled your code, to figure out what needs work, the next step is to actually optimize the relevant parts.



@body - 1608 words
In the last issue, we looked at a few techniques to profile your Python code and figure out which parts of it were most in need of attention. When you are running code on a Raspberry Pi, you only have limited resources. Hence the need to optimize in order to get the most work done that you can. This month, we will look at a number of different techniques that can be used to maximize the amount of RAM and CPU that you have available to you. There are several broad categories of optimization tricks that we will look at, along with a few specific examples. Always remember that the first step is to have code that works correctly. Then you should only do the minimum amount of optimization to get the performance you actually need. Any extra work is essentially wasted, unless you are only interested in using the process as a learning opportunity.

The first item to look at is how strings are handled. Strings are immutable lists of characters. This means that when you want to add more characters to a starting string, you need to make a new string and copy both the old and new characters into the new space. In those cases where you are programmatically building up large pieces of text, all of this moving of characters around in memory can be rather expensive. Instead of using a construct like
   str1 = ""
   for word in list:
      str1 += word
you can use
   str1 = "".join(list)
This essentially builds up the string in a single step, for a reasonable speed up. Since we are looking at for loops anyway, we should look at other things we can do to speed them up. There is a fair amount of overhead involved when Python manages a for loop. If the code within your for loop can be bundled as a function, you can use the 'map' command to have this function run for each value stored within a list. In this way, you can remove the overhead of the for loop, and essentially move the computational content from Python to C. If you can't do the shift to using a map command, another item to look at is whether there are references to object methods. If so, Python needs to do type checking on every call around the for loop. This means that Python needs to check the types of the parameters being handed in, then check to see if there is a valid form of the called method, and finally run the called method. You can remove this overhead by assigning these calls to a new name before entering the for loop. This way, all of this type checking and name resolution only happens once outside the loop. So the code
   for word in oldlist:
      newlist.append(word)
can get replaced with the more efficient code
   append = newlist.append
   for word in oldlist:
      append(word)
This type of checking also happens whenever you use any kind of polymorphic operator or function. So, if you wanted to use the '+' operator, Python needs to check both of the parameters being added together to try and figure out what version of '+' to use. If you do need to use a polymorphic operation inside a very large loop, it might well be worth your time to look at solutions that use strictly defined data types to remove these checks. While this flexibility in data types is a strength of Python, you may need to give up this flexibility in very specific situations to maximize the speed of your code.

If you are doing numerical computation of any kind, you need to start using the numpy module. Numpy provides functionality that improves the performance of Python numerical code close to the performance you would expect to see when using C or FORTRAN. The main way numpy helps is by providing fixed data types, as we mentioned above. The most basic data structure that numpy provides is the array. An array is like a list, except that it can only store elements of one type, and it is the basic building block that everything else is built of within numpy. These arrays are treated as a single data element, so type checks only need to happen once for the entire array. As an example, let's say that you want to multiply the elements of two vectors. In "regular" Python, you would use a loop like
   for index1 in range(50):
      c[index1] = a[index1] * b[index1]
where a and b are vectors of length 50. In this case, every time you run through the loop, Python needs to check the types for a[index1] and b[index1]. This is quite a bit of overhead. By using numpy, and the provided array data structures and functions, you can rewrite this code as
   c = a * b
This makes the code clearer to read. It also only involves a single type check to see whether a and b can be multiplied together. The actual operation then gets passed off to a C library, usually from some linked in linear algebra packages like BLAS or LAPACK. This provides a substantial speed increase because you can take advantage of all of the optimization work that has gone into these external C or FORTRAN libraries.

There are some obscure ways of speeding up your code, too. For example, Python needs to regularly check to see whether something else needs to be done. This something else may be looking to see if a different thread needs to run, or whether a system call needs to be processed. This can take quite a bit in terms of resources. You can use the command 'sys.setcheckinterval()' to change the how long Python waits to run these checks. If you aren't using threads, or making system calls that may be sending signals to your code, you can set this to a higher value to improve the performance of your code. Another more obscure technique that optimizes both memory and speed is to use the xrange command. If you need a list of integers, this is usually handled by the command range. The problem with this command is that the entire list gets created in total and stored in memory. You acces the list through an iterator and walk through each of the elements. The xrange command provides the list of integers through a generator. A generator does exactly what you think it does; it generates the elements that iterate over as they are needed. This means that you only have one element of the list in memory at any particular time. Also, you don't have the wait while the entire list is being generated. If you are looping over a for loop that has a few thousand cycles, or potentially even millions, this switch to using xrange can provide a significant speed boost. If you are iterating over data in a file, you may actually want to do the opposite. Reading from a hard drive can be several orders of magnitude slower than reading from memory. This means that you should read in as much of a file as you can reasonably fit into your available RAM in a single operation to speed up manipulating this data. The last obscure method is to consider the scope of variables. Whenever possible, you should use local variables within a function rather than global variables. Python is much more efficient when accessing variables that are within the same scope as the function body, rather than having to move out one or more layers to whichever code body actually called the function in question.

If all of these techniques don't work, then you can always move to a different language and use this alternate code within Python. As an example, you can use Cython to take optimized C code and make it available within your Python program. There are equivalent techniques for other languages used in high performance applications. There are several cases where the algorithm, available in the alternate language, is just not easily translated to efficient code within Python. In these cases, you have the tools available to leverage this previous work within your own code. We will be looking at this particular technique in greater detail next week. The last technique available is to not use Python at all. At least, not the virtual machine. Python is an interpreted language, which means that every program has the default overhead of having to run through the interpreter rather than running as machine code directly on the hardware. A last resort that is available is to cross-compile your code to machine code for the particular hardware you wish to use. There are a few different projects available, such as nuitka, that can generate this cross-compiled code. Sometimes, you need to give up easy portability to get your code running as fast as possible on any particular piece of hardware.

Now that we have taken a look at a few different ways of speeding up your code, hopefully this article will give enough tools to really do some amazing things with your Raspberry Pi. Not that long ago, techniques like those above were common. It was the only way to get serious work done. The resources available on the Raspberry Pi  are only limited compared to modern standards. With a bit more thought, quite a bit of computational work can be done. Just remember the quote, "premature optimization is the root of all evil" and be sure you invest your time where it will have the greatest impact.



@boxout - 320 words
While you have the ability to use an alternate language within Python, through Cython for example, you can get optimized code and still stay with pure Python. The numba project (http://numba.pydata.org) provides a LLVM just-in-time compiler that translates your Python code to optimized machine code. Once you install the numba module, you can import the jit portion with the statement
   from numba import jit
This provides a function decorator, "@jit", that tells numba to compile the given function to machine code. Every time the compiled function is called, the machine code version is the one that is executed, bypassing the virtual machine. By default, numba needs to check the types of any input variables and compile appropriate code. This means that you may end up with more than one version of the compiled code. Also, you still have the overhead involved in doing the type checking when the function is called. If you know what data types are going to be handed in, you can skip this check by including type information in the decorator. For example, you could have something like
   @jit(int32(int32, int32))
   def f(x, y):
      return x + y
This compiles the one version you need. Numba also uses lazy compilation, which means that it will only compile when the relevant function is first called. This way, only the portions of code that you actually need go through the overhead of the compilation step. You can use the included pycc utility to compile your Python code ahead of time. This will save you even more at runtime. There are limitations on which data types are supported, and how complex the code can be. But it is still effective enough to make it well worth your time to give it a try. This follows a workflow that is more reminiscent of a traditional compiled programming language, while letting you stay within Python.



@code - if you can do some example code all the better. We can style it up properly. Max of 50-70 lines, though. 
