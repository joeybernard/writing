@ Title (2-4 words) - 4 words
Can Your Pi Multitask?



@ Standfirst (20 words approx) - 24 words
Sometimes, you need to keep track of more than one thing at a time. Learn how to add multitasking to your own Python code.



@ Bio (20-30 words) - 23 words
Joey Bernard is a true Renaissance man, splitting his time between building furniture, helping researchers with scientific computing problems and writing Android apps.



@ Body ( = 9400 - P characters, where P = [no. of lines of code in new paragraphs x 35] + [no. of new paragraphs for code x 70], eg 5 lines of code at 35 characters per line, split into 2 separate paragraphs rather than a single paragraph of five lines, means a reduction of 315 characters from the overall character count) - 9648 characters

Almost all programmers learn single-threaded programming as their first computational model. The basic idea is that instructions for the computer are processed sequentially, one after the other. This works well enough in most situations, but eventually you will reach a point where you need to start doing more than one thing at a time. The classical situation for writing multi-threaded applications is to have them run on a multi-processor machine of some persuasion. In these cases, you would have some heavy, compute-bound, process running on each processor. Since your Raspberry Pi is not a huge 16-core desktop machine, you might be under the assumption that you can't take advantage of using multiple threads of execution. This isn't true, though. There are lots of problems that map naturally to the multiple thread model. You may also have IO operations that take a relatively large amount of time to complete. In these cases, it is well worth your programming effort to break your problem down into a multi-threaded model. Since Python is the language of choice for the Raspberry Pi, we will look at how you can add threads to your own Python code. For those of you who have looked into multi-threaded programming in Python, you may have run into the GIL (Global Interpreter Lock) before. This lock means that only one thread can actually be running at a time, so you don't get true parallel processing. But on the Raspberry Pi, this is OK. We just want to use a more natural programming paradigm for certain problems where it makes sense.

The first bit of code we need is to import the correct module. For this article, we will be using the 'threading' module. Once it is imported, you have access to all of the functions and objects that you would need to write your code. The first step is to create a new thread object with the constructor
   t = threading.Thread(target=my_func)
The 'Thread' object takes some function that you have created, 'my_func' in the above example, as the target code that needs to be run. When the thread object has finished its initialization, it is alive but not running. You need to explicitly call the new thread's 'start()' method. This will begin running the code within the function handed to the thread. You can check to verify that this thread is alive and active by calling its 'is_alive()' method. Normally, this new thread will run until the function exits normally. The other way a thread can exit is if an unhandled exception is raised. Depending on your experience writing parallel programs, you may already have some ideas on what types of code you want to write. For example, in MPI programs, you typically have the same overall code running in multiple threads of execution. You use the thread's ID and a series of if or case statements to have each thread execute a different section of the code. To do something similar, you can use something like
   def my_func():
      id = threading.get_ident()
      if (id == 1):
         do_something()
   thread1 = threading.Thread(target=my_func)
   thread1.start()
This code works in Python 3, but the 'get_ident()' function doesn't exist in Python 2. Threading is one of those modules that is a moving target when moving from one version of Python to another, so always check the documentation for the version of Python your are coding for. Another common task in parallel programming is to farm out time intensive IO into separate threads. This way, your main program can continue on with the core work and all of the computing resources are kept as busy as possible. But, how do you figure out if the child thread is done yet or not? You can use the 'is_alive()' function mentioned above, but what if you can't continue without the results from the child thread. In these cases, you can use the 'join()' method of the thread object you are waiting on. This method blocks until the thread in question returns. You can include an optional parameter to have the method timeout after some number of seconds. This allows you to not get trapped into a thread that will never return due to some error or code bug.

Now that we have more than one thread of execution happening at the same time, we have a whole new set of problems that we need to start worrying about. The first is acessing global data elements. What might happen if you have two different threads who want to read, or even worse write, to the same variable in global memory? You can have situations where changes to the value of variables can get out of sync with what you were expecting them to be. These types of issues are called race conditions, because the different threads are racing with each other to see in what order their updates to variables will happen. There are two solutions to this type of problem. The first is to control access to these global variables and only allow one thread at a time to be able to work with them. The generic term describing this control is to use a mutex to control this access. A mutex is an object that thread needs to lock before working with the associated variables. In the Python threading module, this object is called a lock. The first step is to create a new Lock object with
   lock = threading.Lock()
This new lock is created in an unlocked state, ready to be used. The thread interested in using it must call the 'acquire()' method for the lock. If the lock is currently available, then it changes state to the locked state and your thread can run the code that is meant to be protected. If the lock is currently in a locked state, then your thread will sit in a blocked state, waiting for the lock to become free. Once you are done with the protected code, you need to call the 'release()' method to free the lock and make it available for the next thread. As an example, you could control a variable containing the sum of a series of results with code like
   lock.acquire()
   sum_var += curr_val
   lock.release()
This can lead to another common issue in parallel programs, deadlocks. These issues happen when you have multiple locks that are associated to different global variables. Say you have the variables A and B, and the associated locks lockA and lockB. If thread 1 tries to get lockA then lockB, while thread 2 tries to get lockB then lockA, you could have the situation where they each get their first requested lock, and then wait forever for the second requested lock. The best way to avoid this type of bug is to code your program very carefully. Unfortunately, people are only human and messy code always creeps in. So, you can try and catch this kind of bad behaviour by including the optional timeout parameter when you call the 'acquire()' method. This tells the lock to only try and get the lock for some number of seconds. If the timeout is reached, the acquire method returns. You can tell whether or not it was successful by checking the returned value. If it was successful, acquire will return True. Otherwise, it will return False. The second way you can deal with data access is by moving any variables that you can to within the local scope of the individual threads. The essential idea is that each thread would have its own local version of any required variables that nobody else can see. This is done by creating a local object. You can then add attributes to this local object and use them as local variables. Within the function being run by your thread, you would have code that looks like
   my_local = threading.local()
   my_local.x = 42

The last topic we will look at is synchronizing your threads so that they can work together effectively. There will be times when a number of threads will need to talk to each other after working on their separate parts of some problem. The only way they can share their results is if they have all finished calculating their individual results. You can solve this problem by using a barrier, where each of the threads will stop at until all of the threads have reached it. In Python 3, there is a barrier object that can be created for some number of threads. It will provide a point where threads will pause when they call the barrier's 'wait()' method. Because you need to explicitly tell the barrier object how many threads will be taking part in the barrier, this is another area where you can have a bug. If you create 5 threads, but create a barrier for 10 threads, it will never reach the point where all of the expected threads have reached the barrier. The other synchronization tool is the timer object. A timer is a subclass of the thread class, and so takes a function to run after some amount of time has passed. As with a thread, you need to call the timer's 'start()' method in order to start the countdown to when the function gets executed. A new method, 'cancel()', allows you to stop the countdown of the timer if it hasn't reached zero yet.

You should now be able to have your code running even more efficiently by farming out any time intensive parts to other threads of execution. In this way, the main part of your program can remain as reactive as possible to interaction with the end user and you can keep all parts of your Raspberry Pi as busy as possible.


@ Boxout title (2-4 words) - 5 words
Using Processes Instead of Threads



@ Boxout text ( = 2200 - Q characters, where Q = [no. of lines of code in new paragraphs x 45] + [no. of new paragraphs for code x 90] ) - 2137 characters

What if you need to actually have truly parallel code, that has the ability to run on multiple cores? Because Python has the GIL, you need to move away from using threads and go to using separate processes to handle the different tasks. Luckily, Python includes a multiprocessing module that provides the process equivalent to the threading module. As with the threading module, you create a new process object and hand in a target function to be run. You then need to call the 'start()' method to get it running. With threads, sharing data is trivial because memory is global and everybody can see everything. But, different processes are in different memory scopes. In order to share data, we need to explicitly set up some form of communications. You can create a queue object where you can transfer objects. Processes can use the 'put()' method to dump objects on the queue, and other proceses can use the 'get()' method to pull objects off. If you want a bit more control over who is talking to who, you can use pipes to create a two-way communication channel between two processes. When you use pipes and queues, you need to hand them in as arguments to your target function. The other way you can share information is by creating a section of shared memory. You can create a single variable sharelocation with the Value object. If you have a number of variables you need to pass, you can put them in an Array object. As with pipes and queues, you will need to pass them in as parameters to your target function. When you need to wait for the results from a process, you can use the 'join()' method to get the main process to block until the sub-process finally finishes.

The processing module also includes the idea of a process pool that is different from the threading module. With a pool, you can pre-create a number processes that can be used in a map function. This kind of construct is useful if you are applying the same function to a number of different input values. For people who are used the concepts of mapping or applying functions from R, or Hadoop, this might be a more intuitive model to use in your Python code.



@ Full code listing (optional, no more than 50 lines of code at 70 characters per line; if this is supplied, change the body text to (6100 - P) characters)
