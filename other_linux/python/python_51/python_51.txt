@ Title (2-4 words)  -  6 words
Using Numba to Speed Things Up



@ Standfirst (20 words approx)  -  23 words
This month, we look at numba as a tool that you can use with your Raspberry Pi Python code to speed everything up.



@ Bio (20-30 words)
Joey Bernard is a true Renaissance man, splitting his time between building furniture, helping researchers with scientific computing problems and writing Android apps



@ Body (1,620 words, REDUCE your word count by 24 words for one line of code (each line is roughly equal to 8 words and we have a line break before and after code), 32 words for 2 lines, 40 words for 3 lines and so on)  -  1675 words

We have looked at a lot of various packages and programs, written in Python, for your Raspberry Pi projects. One area that is always an issue with Python code is performance. Much of these problems are due to using programming techniques from other languages that simply don't work the same way in Python. These types of issues are usually dealt with by rewriting your code in a more Pythonic form. While this is perfectly adequate in most cases, people are always keen to squeeze every last bit of performance out of their code. This month, we are looking out for those people. In these cases, you have a few different options. You could use a module, like Cython, to recode any problem areas in your code into compiled C code. Another option is to use a specialized Python interpreter that does JIT (Just-In-Time) compiling of code, like Pypy. This issue, we will look at another option, named numba, which compiles your code with a JIT compiler based on additions to your code. This allows you to fine tune how the JIT compiler works. This has been an issue on Raspberry Pis, since it requires the LLVM compiler and it hasn't been easily available on ARM architectures. But, since the latest versions of Raspbian, there is a llvmlite package available, allowing you to use numba. In order to install it on your Raspberry Pi, you should probably follow the instructions below.
   sudo apt install libblas-dev llvm python3-pip python3-scipy
   pip install llvmlite==0.15.0
   pip install numba==0.30.1
   pip install librosa
You do need to be careful of version numbers, as this does require patches that may not be part of the stable branches. Depending on your setup, you may want to do this inside a virtualenv. If so, you will want to run the following commands before the pip commands earlier.
   virtualenv --system-site-packages -p python3 env
   source env/bin/activate
If you are doing development on another box, you probably want to be using an Anaconda installation. If so, you can install numba with the following command.
   conda install numba
Now that it is installed, let's take a look at what you can do with numba.

Numba does code optimization based on decorators that you can add to your code. These decorators invoke the LLVM compiler to generate code tuned to your particular CPU architecture. The easiest way to use it is to use the default lazy compilation process on your defined functions. The following is a trivial example.
   from numba import jit
   @jit
   def my_sum(x, y):
      return x+y
Lazy compilation means that numba won't bother compiling a particular decorated function until the first time it is called. At that time, the input parameters are analyzed for type and a specialized compiled version is generated. Because the compiled version depends on the input types, a new version gets generated when input parameters of different types get used. This preserves the naturally polymorphic nature of Python. In many cases, however, you know what the datatypes are supposed to be for a particular function. In these cases, you can tell numba what it should be expecting in terms of datatypes. This would make the code above look like the following.
   @jit(int32(int32,int32))
   def my_sum(x, y):
      return x+y
This change tells numba that it should generate code that takes int32 as input datatypes and that it should return int32 datatypes. There are several options you can give to numba to help get the fastest code possible. This greatly depends on what your code is actually doing and is very much of the form "Your mileage may vary" types of options. The first to look at is the 'nogil' option. If your code is thread safe and will not impact, nor be impacted by, other threads, you can explicitly tell numba that it can give up any locks on the GIL (Global Interpreter Lock). This would look like the following.
   @jit(nogil=True)
Normally, these compiled code objects only exist during the runtime of your object. You can save the compilation step by adding the 'cache=True' option to the jit decorator. This tells numba to save any compiled objects in files on the filesystem so that they are available the next time you run your program. By default, the code generated by numba tries to be as optimized as possible. This means that the code generated does not use the Python C API. If numba can't produce code in this mode (referred to as nopython), it will fallback to generating code that does use the Python C API (referred to as object). If you want to know when this happens, you can add the option 'nopython=True' to the jit decorator. This tells numba to throw an error when it needs to fallback, rather than simply doing it silently. This option is necessary if you want to try the latest experimental feature, automatic parallelization. The jit decorator would look like the following.
   @jit(nopython=True, parallel=True)
This will analyze your function and see if it can be parallelized, as well as seeing if many other optimizations can be applied.

There will be cases where you want even more fine-grained control over what numba will do with particular functions. In these cases, you will want to use the '@generated_jit' decorator rather than the '@jit' decorator. The big difference is that you have more control over the datatypes used. For example, the above example would look like the following.
   from numba import generated_jit, types
   @generated_jit(nopython=True)
   def my_sum(x, y):
      if isintance(x, types.Float):
         if isinstance(y, types.Float):
            return x+y
This decorator also accepts the other compiler options, such as 'nopython' and 'cache'.

While the default operation of numba works on the assumption that it will be used as a JIT compiler, this is not the only way that you can use it. You can use the AOT mode (Ahead-Of-Time) in order to compile the necessary functions before they are used. The big advantage of this comes into play when you wish to distribute your program with other people. If you use the default JIT activity, then anyone you share the code with will need to have numba installed. Using the AOT functionality means that they will be able to run your optimized code without having to have them install the numba Python module. In order to take advantage of this functionality, you need to import the CC portion of the numba module. The biggest restriction is that you need to define everything up front, as you would with a traditional programming language. A simple example would look like the following.
   from numba.pycc import CC
   cc = CC('my_module')
   @cc.export('multf', 'f8(f8, f8)')
   @cc.export('multi', 'i4(i4, i4)')
   def mult(a, b):
      return a * b
   if __name__ == "__main__":
      cc.compile()
In the above example, we have two versions of the multiplication function defined, one for integers and one for floats. When you run this code, numba produces a compiled module, named 'my_module', that you can then share with other users. When you import the compiled module 'my_module', your users will have access to the numba compiled versions of these functions.

There are several other options to tune the behavior of numba. One example is the '@jitclass' function decorator. This decorator defines a specification for a class so that numba can compile a specific version for your particular use-case. The following code provides an example.
   import numpy as np
   from numba import jitclass
   from numba import int32, float32
   spec = [('value', int32),('array', float32[:]),]
   @jitclass(spec)
   class Bag(object):
      def __init__(self, value):
         self.value = value
	 self.array = np.zeros(value, dtype=np.float32)
As you can see, you can optimize entire classes as well as individual functions.

Hopefully this short article has given you some ideas that you can use for your own projects. There are several ways to speed your Python code up, and while this is only one way, it should at least give you a place to start.


@ Boxout title (2-4 words)  -  4 words
What about other interpreters?



@ Boxout text (440 words, again, REDUCE your word count by 24 words for one a single line of code (each line is roughly equal to 8 words and we have a line break before and after code), 32 words for 2 lines, 40 words for 3 lines and so on).  -  389 words

While numba allows you to compile sections of your code to get speedups, there are other options available. The simplest, most direct option available is to use a different interpreter. This allows you to get better performance without necessarily having to do anything. As all programmers know, you should always follow the laziest path available. Installing Pypy on a Debian-based system should be as simple as the following command.
   sudo apt-get install pypy
This will install a new Python interpreter for you to use on your system. One thing to be aware of is that the performance of Pypy is dependant on the architecture that you are running the code on, so you may notice different speedups on your Raspberry Pi (based on the ARM), as opposed to your regular x86-based desktop. In many cases, you can get a speedup by simply calling you script as the following.
   pypy myscript.py
You can maximize this speedup by following some rules of thumb.

One rule of thumb is to look at how your code is bound. If it is IO bound, then Pypy isn't going to really help. This is defined by hardware. Pypy can help most for code that is compute bound. Having said that, you should still follow the usual rules. You should make sure that your algorithm is as tuned as possible before applying extra external options, like the pypy interpreter. There are also some items that should avoid. You won't want to necessarily use C extensions with pypy. You may not see any advantage in these cases. Also, the use of Ctypes may actually see a decrease in performance. As with most variations in programming language and technique, your mileage will vary, and you will need to tune your code to the specific tasks that you want to handle. To this end, pypy includes a module of code that can be imported into your own code. This gives you the tools you need to further fine tune its behavior so that you can squeeze every last bit of performance out of your code.




@ Full code listing (optional, no more than 50 lines of code at 70 characters per line
xxxx

Imagery – if you have any suggestions for illustrating the column, please supply them as we usually put something in the section introduction.
