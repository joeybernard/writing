
@ Title  -  10 words

Using Tensorflow to Classify Images - Putting Neural Networks to Work



@ Standfirst  -  21 words

Tensorflow has given everyone the power of a deep learning library. This has made possible a huge number of advanced projects. 



@ Profile
[Joey Bernard]

Joey Bernard has written a column on scientific software, as well as a column on writing Python code for the Raspberry Pi. In his day job, he helps researchers and students at the university level in designing and running HPC projects on supercomputing clusters.



@ Resources
https://www.tensorflow.org/
https://github.com/tensorflow/tensorflow
https://github.com/tensorflow/models



@ Lead image
I think something around the tensorflow logo would be appropriate here.



@ Intro text  -  199 words

Neural networks have been around, as an idea, since the very beginning of artificial intelligence research. The problem has always been that it is very difficult to implement them in an efficient way. This has kept these techniques out of the hands of the average software developer. This has been the case until Google developed a library for the Google Brain internal project. This library was releases as an open source library named Tensorflow. Tensorflow has been out in the wild since 2015. In just a few short years, it has found its way into a huge number of fields and projects, including convolutional neural networks, audio recognition and image recognition, among others. In this article, we will look at how Tensorflow can be used to do image recognition and classification. Because it has shown its usefulness, Tensorflow has been ported to many different platforms. This has included, most recently, mobile platforms such as Android and Apple smart phones. We will look at how to get it installed on your platform, and how to a basic system setuo so that you can do some image processing. Don't forget that there is loads of other functionality available in Tensorflow, too.



@ Body text  -  2744 words

@ Heading 1  -  Installation
The first step is to get Tensorflow installed on the machine where you will be doing all of this image analysis work. For most platforms, you should be able to install it using pip. Because we only have room to talk specifically about one platform, I will assume that you are using a Debian-based Linux distribution. Assuming this, you can install the necessary tools with the following command.
/c/
sudo apt-get install python3-pip python3-dev python-virtualenv
/c/
In order to keep your Python enviornment organized, you should create a virtual environment where you can safely install Tensorflow. You can do this with the following.
/c/
virtualenv --system-site-packages -p python3 tensorflow
/c/
This will create a virtual environment, in the subdirectory named 'tensorflow', where you can install Tensorflow. You can activate it by sourcing the activation script.
/c/
source ~/tensorflow/bin/activate
/c/
/o/
(tensorflow)$
/o/
Your command line prompt should change to the new one seen above. You can now install Tensorflow into the virtual environment with
/c/
(tensorflow)$ pip3 install --upgrade tensorflow
/c/
This installs the CPU version of the Tensorflow library. However, much of the processing that it does can be farmed out to a GPU for faster results. If you have an Nvidia card, you can use the following commands to install the required CUDA support package and install the GPU version of Tensorflow.
/c/
sudo apt-get install cuda-command-line-tools
source ~/tensorflow/bin/activate
pip3 install --upgrade tensorflow-gpu
/c/
You should verify that everything installed correctly. You can run the following tiny piece of code.
/c/
import tensorflow as tf
hello_test = tf.constant('Hello from TensorFlow!')
sess = tf.Session()
print(sess.run(hello_test))
/c/
You should get the following output.
/o/
Hello from TensorFlow!
/o/
Assuming you see this output, you should be good to go on and actually get some work done.

@ Heading 2  -  Basic Ideas
In Tensorflow, there is a core concept of the graph. Data is imported into variables with some relationship between the elements. There is also a series of processes that need to be applied to the data. All of these processes and relationships are combined to define a dataflow graph. Tensorflow then acts as the engine that traverses these graphs and executes all of the operations that have been defined. All of these features are accessible through the low-level API in Tensorflow, but most people don't need to work with that much detail. There is a higher-level API that provides data import functions that can manage creating the data structures from many common data file formats. Then, there are a series of functions called estimators. These estimators create entire models, and the underlying graphs, so that you can simply run the estimator to do the data processing that is needed.

@ Heading 3  -  Inception-v3
One of the tasks that Tensorflow has shown its usefulness for is image recognition. This means that a lot of work has been done to improve the performance. When you start developing your own algorithms, the work done in the image recognition estimators would be well worth your time to investigate. One family of image recognition estimators is named inception. It has been released in a series of version, with the most current being version 3. The inception models were trained using a data set called ImageNet. This collection was put together in 2012 to act as a standard set to test and compare image recognition systems. It consists of over 14 million images in 1000 categories.

Luckily, inception-v3 is a fully trained model that you can download and use to experiment. Once you have Tensorflow installed, you can download inception from the github repository with the following commands.
/c/
git clone https://github.com/tensorflow/models.git
cd models/tutorials/image/imagenet
/c/
In this folder, you will find the Python script 'classify_image.py'. Assuming you have never run this script before, or downloaded the model data at some other time, it will start by downloading the file 'inception-2015-12-05.tgz' so that it has the model data. If you did already download the model, you can tell this script with the command line option '--model_dir'. In order to have it classify your own images, you can hand them in with the command line option '--image_file'. If you are just testing it, you can use the default image of a panda. When you run it, you should get output like the following.
/c/
python ./classify_image.py
/c/
/o/
giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca (score = 0.89107)
indri, indris, Indri indri, Indri brevicaudatus (score = 0.00779)
lesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens (score = 0.00296)
custard apple (score = 0.00147)
earthstar (score = 0.00117)
/o/
As you can see, it gives you the top 5 matches for what Tensorflow thinks your image might be with a confidence score. If you want, you can change the number of returned matches with the command line option '--num_top_predictions'.

@ Heading 4  -  Tuning the net
While the inception model is very good, it is designed to be as general as possible and be able to identify a wide range of categories. But, you may want to tune the model to be even better at identifying some smaller subset of types of images. The model is a multi-level neural network that has been trained. In these cases, you can reuse the bulk of the inception model and just replace the last layer of the neural network to be specific for your new image category. In the main tensorflow github repository that you need to download, there is a Python script that gives an example of how to retrain the inception model.
/c/
python tensorflow/examples/image_retraining/retrain.py --image_dir ~/my_images
/c/
This script takes all of the images in the directory 'my_images' and retrains the model using each image. This simple a retraining process can still take 30 minutes or more. If you were to do a full training of the model, this could take a huge number of hours. There are several other options available, including selecting a different model to act as a starting point. There are other smaller models that are faster, but not as general. If you are writing a program to be run on a lower power processor, such as in a phone app, you may decide to select one of these instead.

@ Heading 5  -  Training on new data
While the above example may be fine for the majority of people, there may be cases where you need more control than this. In these cases, you can manually manage the retraining of your model. The first step is to load the data for the model. The following code lets you do this.
/c/
graph = tf.Graph()
with graph.as_default():
   with tf.gfile.FastGFile('classify_image_graph_def.pb', 'rb') as file:
      graph_def = tf.GraphDef()
      graph_def.ParseFromString(file.read())
      tf.import_graph_def(graph_def, name='')
/c/
This loads the model and creates a new graph object. The graph is made up of several layers, all leading to a final output layer.
/c/
last_layer = graph.get_tensor_by_name('pool_3:0')
/c/
This final layer is what does the final classification and makes the final decision as to what your image is. At this point, you can process your specialized images to create a new final layer. There are several steps required in order to preprocess the images, and then train a new final layer.

@ Heading 6  -  TF-slim
As you can see, we have only touched the code necessary in the most cursory way in the material above. We haven't had the space available to dig into much of the detail that you require in order to get any work done. This is a well known complaint people have with Tensorflow. To help alleviate this issue a wrapper layer of code, named tf-slim, that minimizes the amount of code that you need in order to get some useful work done. It is available in the contrib portion of the tensorflow installed package. You can import it with the code below.
/c/
import tensorflow.contrib.slim as slim
/c/
Now, with the tf-slim module loaded, a lot of the boilerplate code that needs to be written when working in tensorflow is wrapped and taken care of for you. In tf-slim, models are defined by a combination of variables, layers and scopes. In regular tensorflow, creation of variables requires quite a bit of initialization on whichever device the data is being stored and used on. Tf-slim wraps all of this so that it simplifies to become a single function call. For example, the following code creates a regular variable containing a series of zeroes.
/c/
my_var = slim.variable('my_var', shape=[20, 1],
                       initializer=tf.zeros_initializer())
/c/
Getting the list of variables in the model is also simplified to the follow.
/c/
regular_variables_and_model_variables = slim.get_variables()
/c/
Building layers for a neural network under tf-slim is also greatly simplified. In plain tensorflow code, creating a single convolutional layer can take 7 lines of code. In tf-slim, this collapses down to the following 2 lines of code.
/c/
input = ...
net = slim.conv2d(input, 128, [3, 3], scope='conv1_1')
/c/
Tf-slim also includes 13 other builtin options for layers, including fully connected and unit norm layers. It even simplifies creating multiple layers with a repeat function. For example, the following code creates 3 convolutional layers.
/c/
net = slim.repeat(net, 3, slim.conv2d, 256, [3, 3], scope='conv3')
/c/
This makes the task of retraining a given model to be more finely tuned much easier. You can use these wrapper functions to create a new layer with only a few lines of code and replace the final layer of an already built model. Luckily, there is a very good example of how you can do this available within the models section of the tensorflow source repository at github. There is a complete set of Python scripts written to help with each of the steps that we have already discussed. There are scripts to manage converting image data to the tensorflow TFRecord data format, as well as scripts to automate the retraining of image recognition models. There is even an IPython notebook, named 'slim_walkthrough.ipynb', that takes you through the creation of a new neural network, training it on a given dataset, through to the final application of the neural network on production data.

Once you have a new layer constructed, or perhaps you have created an entirely new neural network from scratch, you still have to train this new layer. In order to retrain a given network, you need to create a starting point with the following code.
/c/
model_path = '/path/to/pre_trained_on_imagenet.checkpoint'
variables_to_restore = slim.get_variables_to_restore(...)
init_fn = assign_from_checkpoint_fn(model_path, variables_to_restore)
/c/
Once you have this starting point, you can start the retraining with the code below.
/c/
train_op = slim.learning.create_train_op(...)
log_dir = '/path/to/my_model_dir/'
slim.learning.train(train_op, log_dir, init_fn=init_fn)
/c/
You can then run this newly created model to get it to do actual work. To help, the tf-slim code repository includes a script, named 'evaluation.py', to help you do this processing step. If you have something specific that you need to do, you can use this script as a starting point to write your own workflow scripts.

@ Heading 7  -  Performance?
The developers behind tensorflow has put a lot of work behind making the final, trained models fairly snappy in terms of performance. This is one of the reasons why deep learning and neural networks have been exploding recently. There is still one area that has performance problems, however; that is the training of the models in the first case. For example, training the inception image recognition model takes weeks of processing time. This is why quite a bit of development time has been put into including GPU support for this stage of tensorflow usage. This is why you should use a pre-trained model, such as the inception model we have been discussing, whenever you have the opportunity. The Inception-V3 model took weeks, even with 50 GPUs crunching the network data. When you are doing your own training, there are few things you can do to help with performance. One of them is to try and bundle your file IO into larger chunks. Accessing the harddrive is one of the slowest pieces of a computer. If you can take multiple files and combine them into larger collections, reading them in is made more efficient. The second option you have is to use fused operations in the actual training step. This takes multiple processing operations and combines them into single fused operations to minimize function call overhead.

@ Heading 8  -  Where to?
We have only been able to cover the process of image recognition and retraining of neural networks in the most superficial way. There are a large number of complicated steps involved in working with these types of models. My hope is that this short article has been able to hightlight the overall concepts, and included enough external resources to help point you to sources of the details you would need to be able to add this functionality to your own projects.



@ Supporting images
image1  -  neural_net.png
image2  -  slim_walkthrough.png
image3  -  tensorflow_structure.png



@ Captions
image1  -  A neural network consists of an input layer, a number of intermediate layers, and then an output layer.
image2  -  In the models repository for tensorflow, there is a complete tutroial available as an IPython notebook.
image3  -  Tensorflow has a layered structure, building up from a core graph execution engine all the way up to high-level estimators.



@ Boxout1  -  66 words
Visualizing models with Tensorboard

When working with networks and models, it can become difficult to figure out what is actually happening. To help, the developers have provided a tool, called tensorboard, to help visualize the learning that is being processed. In order to use it, you do need to have your code generate summary data, which can then be read in by tensorboard to see detailed information for you model.



@ Boxout2  -  56 words
Moving to the Real World with Tensorflow Mobile

When you have a model trained and are using it in some project, you have the ability to move it onto what may seem like underpowered hardware by using the Tensorflow Mobile libraries that are available at the tensorflow site. This can move very intenive deep learning application out to devices like smart phones or tablets.



@ Pullquote1  -  21 words
In Tensorflow, there is a core concept of the graph. Data is imported into variables with some relationship between the elements.

@ Pullquote2  -  30 words
Now, with the tf-slim module loaded, a lot of the boilerplate code that needs to be written when working in tensorflow is wrapped and taken care of for you.

[IMAGE USAGE FORM INFO: PLEASE GIVE COMPANY AND CONTACT DETAILS FOR THE IMAGES USED IN THIS FEATURE]
