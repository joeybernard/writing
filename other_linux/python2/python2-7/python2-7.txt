
@ Title  -  9 words
Using ipyparallel to put your Raspberry Pis to work



@ Standfirst  -  30 words
There are lots of methods to run parallel code on your network of Raspberry Pis. This month, we will look at how to use ipyparallel to run parallel Python code.



@ Profile  -  44 words
[Joey Bernard]
Joey Bernard has written a column on scientific software, as well as a column on writing Python code for the Raspberry Pi. In his day job, he helps researchers and students at the university level in designing and running HPC projects on supercomputing clusters.



@ Resources
https://github.com/ipython/ipyparallel
https://ipyparallel.readthedocs.io/en/latest/
https://github.com/jjhelmus/berryconda



@ Lead image
I was thinking of something where we have multiple Python logos, linked by arrows to the Jupyter logo. Implying parallel Python engines.



@ Intro text  -  185 words
Raspberry Pi provides a very powerful, yet very energy efficient, computing package. While its portability has made a great platform for mobile applications, there is a lot of "real" computing that can be done on them as well. This month, we will look at how you can run parallel Python code on a network of Raspberry Pis. Specifically, we will look at setting up a cluster of Raspberry Pis with ipyparallel, and how to run parallel code on this cluster.

You will want to start by physically connecting the Raspberry Pis together over a network. This may be a small local network, where they are all connected to same router or switch. In all of the examples in the rest of this article, I will be assuming that the Raspberry Pis all have static IP addresses in the range of 192.168.0.1 to 192.168.0.255, since these are reserved for internal local networks. From here, we will move on to setting up the software and actually running jobs. You should end up with probably the quietest and most energy efficient supercomputing.



@ Body text  -  2657 words
@ Subheading 1  -  Introduction
Ipyparallel is a Python module that adds the ability to run multiple IPython engines and have them talk to each other. These could be on a single machine, but in order to maximize the amount of computing you can do, they can be run on multiple separate machines. Ipyparallel is built on a layered structure of three main parts: a controller, one or more clients and one or more engines. The engines are the IPython kernels that actually run your Python code. In our setup here, these engines will be distributed across all of the connected Raspberry Pis. The clients are the Python programs that connect to your ipyparallel cluster and request for computations to be done. This is where you actually define the tasks that need to be done and fire them off. The controller is the core of your ipyparallel cluster. It is actually made up of a hub and one or more schedulers. The hub manages the entire cluster and all of the communications between all of the parts. The schedulers wrap the engines and manage the amount of work being given to them.

@ Subheading 2  -  Installation
The first step is to install ipyparallel on your Raspberry Pi. It is not likely to be in the package repository of whatever distribution you are using. This means that in most cases, you will need to install it using pip. This also means that you will need to install pip first. In Debian-based distributions, like Raspbian, you can install it with the following command.
/c/
sudo apt-get install python-pip
/c/
If you are using Python 3.X, you will want to install 'python3-pip' instead. Once pip installed, you can install ipyparallel with the following command.
/c/
sudo pip install ipyparallel
/c/
If you are using Python 2.X, you may run into an issue here. The latest versions of ipyparallel don't support older versions of Python 2.X and 3.X, and you are more likely to have an older version of Python 2.X. This is because most projects are moving to Python 3.X. If you run into this problem, your two choices are either to move to Python 3.X or install an updated Python 2.X. That will depend on the other requirements of your project. While you don't necessarily need to do the same thing on every Raspberry Pi, especially the clients, it is probably the easiest way to make sure that all of the support libraries and Python modules are installed. So, for the rest of this article, I will assume that you went ahead and simply installed the full ipyparallel module on all of the Raspberry Pis being used.

@ Subheading 3  -  Setting up the master
The master Raspberry Pi node will be the main controller that will be called the master node in the rest of this article. On this master node, you need to start up the controller portion of ipyparallel so that all of the other nodes have somewhere to connect to. The program you use for this step is the 'ipcontroller' executable. One of the most important command line options to this command is '--ip=XXXX', where 'XXXX' is the IP address that the ipyparallel controller is allowed to listen on. If your Raspberry Pi cluster is completely isolated on its own private network, you can set this option to '*'. The complete command would look like the following.
/c/
ipcontroller --ip='*'
/c/
Otherwise, you should be sure to set this to the IP address of the master node. Once this has started up, you will see diagnostic messages being printed out to the terminal window where you started the controller. Some of these messages include the location of several files being created. On my machine, this happens to be '/home/jbernard/.ipython/profile_default'. One of the files, './security/ipcontroller_engine.json', will be used in the next section of this article. There are also several other files, some of which we will look into.

You should have noticed that all of these files are located under the subdirectory 'profile_default'. Ipyparallel uses profiles to allow you to have tuned configurations for different situations. You have a default one created the first time you start the ipcontroller program, and it gets used unless you say otherwise. If you have more than one use-case in mind, you can create a new profile with the following command.
/c/
ipython profile create --parallel --profile=myprofile
/c/
You can then use it by adding the command line option '--profile=myprofile'. All of the options that we have been including in the ipcontroller command can all be placed in configuration files in the profile directory. For example, the command line option '--ip=' would have the following lines placed in the file '/home/jbernard/.ipython/profile_default/ipcontroller_config.py'.
/c/
# in ipcontroller_config.py
HubFactory.ip = '*'
/c/
The documentation covers many more options that you can configure to tune your controller.

@ Subheading 4  -  Setting up the clients
The bulk of your Raspberry Pis will be setup as clients to execute all of the parallel code that you will be running. These clients need to be configured so that they know where the controller is running. They also need to be able to authenticate with the controller, so that they will be allowed to connect. This is where the file '/home/jbernard/.ipython/profile_default/security/ipcontroller_engine.json', from the master node, comes into play. You will need to copy this file to the directory '.../security/' on each of the Raspberry Pi engine nodes. Once this has been done on each engine node, you can start them with the following command.
/c/
ipengine --file=/path/to/my/ipcontroller-engine.json
/c/
The engines also use profiles, just like the controllers. You can create specific ones for special use-cases. In a similar fashion to the controller, the engines can use a configuration file. Specifically, they will use the file 'ipengine_config.py' in the profile directory. You can configure things like some command to run at start up, as in the example below.
/c/
c.IPEngineApp.startup_command = 'import numpy, scipy'
/c/
This would be a good choice if you were going to be doing scientific computations. After reading the relevant documents, you should be able to do quite a bit of tuning to the engines.

@ Subheading 5  -  Running a test
Now that your cluster is up and running, how do you test it? Of course, you need to write a "Hello World" program. You initialize your program with the following code.
/c/
import ipyparallel as ipp
c = ipp.Client()
/c/
This should work if you run it on the master node. If you are actually running on yet another machine, you will need to point to the 'ipcontroller-client.json' file as a parameter to the call to 'Client()'. You also have the option of including parameters to setup an SSH connection, if your network configuration requires you to do so. You can verify that your Client object can see all of the engines with the following.
/c/
c.ids
/c/
/o/
[0,1,2,3]
/o/
This is assuming that you have 4 engines fired up. The following code actually handles the "Hello World" part of your program.
/c/
c[:].apply_sync(lambda : "Hello World")
/c/
/o/
[ 'Hello World', 'Hello World', 'Hello World', 'Hello World' ]
/o/
As you can see, this line selects all of the IDs from the Client object c and calls 'apply_sync()' on them, where a lambda function is handed in as the function to be applied. The lambda function simply returns the string 'Hello World'. Assuming you did not run into any problems, you should be good to move on to more productive work.

@ Subheading 6  -  Running tasks  
Now that you have a functioning ipyparallel cluster, how do you put it to use? If you have done any type of parallel programming in another language, you may be used to the workflow of scattering your data, running your code and then gathering your results. The first step is to create a DirectView object that you can use. This is as simple as the following code.
/c/
dview = c[:]
/c/
For this example, we will get our cluster to calculate the first 64 powers of 10.
/c/
dview.scatter('x',range(64))
%px y = [i**10 for i in x]
/c/
/o/
Parallel execution on engines: [0, 1, 2, 3]
/o/
As you can see, we create a list of 64 integers and scatter them using the variable name 'x'. The second line uses the magic '%px' to execute the single Python command 'y = [i**10 for i in x]'. Ipyparallel has a full selection of magic commands, similar to IPython. The following code gets the results from this parallel run.
/c/
y = dview.gather('y')
print y
/c/
/o/
[0, 1, 1024, 59049, 1048576, 9765625, 60466176, 282475249, 1073741824,...]
/o/
This gathers the results from the remote 'y' variables and stores them in the local 'y' variable.

One issues with the above code is that all of the work simply divided across all of the engines. If one or more of the engines is faster than the others, it could be picking up work from the slower engines. If this is a possible outcome in your situation, you can use the load-balanced view, rather than the direct view, to manage the work being sent to the engines. You can get this view with the following code.
/c/
lview = c.load_balanced_view()
/c/
With this load-balanced view, we can duplicate the above example with the following code.
/c/
lview.block = True
result = lview.map(lambda x:x**10, range(64))
/c/
The first line tells ipyparallel to block until all of the results are calculated and returned. The second line uses the map method of the load-balanced view to get the work of calculating the powers of tens scattered to all available engines. By default, ipyparallel hands out one task at a time. In your particular algorithm, you may know that it makes more sense to hand out tasks 10 at a time to each engine. You can do this by adding the parameter 'chunksize=10' to the call to the map method.

One thing to note is what to do when you use non-blocking calls to map or apply. In these cases, you will get an 'AsyncResult' object returned. This happens before the results are done, which means that it is your responsibility to check to see when they are actually finished. A transparent way of working with the results is simply iterating over them, as in the following example.
/c/
for i in enumerate(result):
    print(i)
/c/
If, instead, you want to simply check in on your progress before starting to work with the results, you can use the progress property of the AsyncResult object to see how many tasks have been completed. You can use this to take care of other pieces of work while periodically checking to see whether all of the tasks have finished or not. Once it equals the number of tasks that have been farmed out, you know that all of the work is done. You could use it to display a progress bar with something like the following.
/c/
fractional_progress = 1.0 * async_result.progress / len(async_result)
/c/
This something that is done often enough to have its own method, 'wait_interactive()'. This lets your end user know that work is still being done when you hit a point where you need to wait for results to finish being calculated.

@ Subheading 7  -  Connecting from jupyter
All of the examples above assume that you are just running Python code directly within the interpreter, or as scripts. But, a growing number of people see the jupyter notebook as their first exposure to Python, especially in data science. Thankfully, the jupyter notebook is able to talk to your ipyparallel cluster and farm work out to it when you get into larger problems. While you can have very complex configurations, we only look at the simplest. If you run the jupyter notebook on the master node, using the same profile that you used to run the ipcontroller program, then the jupyter process should be able to find all of the needed configuration files. You can see the available ipyparallel clusters in the 'IPython Clusters' tab of the notebook. This functionality seems to be fairly brittle, at least in my experience, so you may end up sticking with the basic ipython interface. It very much seems like a 'your mileage may vary' situation. Hopefully you will have good luck if jupyter notebooks are your preferred interface. An option to consider if you do run into issues is to not use your system installation of Python, but instead to move to berryconda, the port of Anaconda to the Raspberry Pi. You may have better luck with this as your environment.

@ Subheading 8  -  Where to now?
Hopefully, this article has given you enough information to put all of those Raspberry Pis that you have been collecting to some serious computational work. You can have the most power efficient supercomputer in your neighborhood. In all seriousness, though, this is a really inexpensive way to start to teach computer science techniques around parallel programming, so well worth your time to explore.



@ Supporting images
@ Image1  -  two_digit_counts.png
@ Image2  -  ipyparallel_architecture.png
@ Image3  -  ipyparallel_tab.png



@ Captions
@ Caption1  -  25 words
You can do rather larger problems going parallel, such as calculating the number two-digit pairs in in the first 150 million digits of pi.

@ Caption2  -  11 words
Ipyparallel is built with a controller, managing several separate computing engines.

@ Caption3  -  18 words
Your ipyparallel clusters are visible from the jupyter notebook, listed in the cluster tab of the web interface.



@ 2x boxouts

@ Boxout1  -  67 words
By default, the control JSON files only exist while ipcontroller is running. If you want to keep them and reuse them, you can add the command line option '--reuse' to the ipcontroller command. This way, you won't need to update the JSON files being used by the ipengine processes. Otherwise, you will need to copy over the new JSON files each time you restart the cluster.

@ Boxout2  -  54 words
If you wish to, you can combine ipyparallel with MPI. This is familiar to anyone who has done parallel programming on traditional high performance computing clusters. You can either use the option '--engines=MPIEngineSetLauncher' to the ipcluster command, or you can use mpiexec to explicitly start ipengine processes across the network of machines.


@ 2x Pullquotes

@ Pullquote1  -  22 words
Ipyparallel is built on a layered structure of three main parts: a controller, one or more clients and one or more engines.

@ Pullquote2  -  23 words
The bulk of your Raspberry Pis will be setup as clients to execute all of the parallel code that you will be running.

[IMAGE USAGE FORM INFO: PLEASE GIVE COMPANY AND CONTACT DETAILS FOR THE IMAGES USED IN THIS FEATURE]
